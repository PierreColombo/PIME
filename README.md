# PIME: Python Information Measures Estimation

Pour la doc: https://pythonot.github.io/


Pour la doc: https://docs.readthedocs.io/en/stable/tutorial/



Pour la To-do list: https://www.notion.so/305cd6b61831453db1e0f6b52b113d81?v=9dfa802a5b4f4e5f97e789f1ef6d0356


Pour Moi il y a deux parties: pour les measures de similarité


Discret Discret (ce que j'ai codé dans InfoLM)
 - Entre deux measues:
    - F divergences
    - Fisher Rao
    - LP distances
 - Sur une seule measure
    - Entropy

Continue Discret (ce que Malik a codé dans son TIM):


Continue Continue:
  - Entre deux measues:
    -  Mutual information
    -  Les closes formes gaussiennes
  - Sur une seule measure:
    - Entropy  
